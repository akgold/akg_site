[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Alex K Gold",
    "section": "",
    "text": "Alex leads the Solutions Engineering team at RStudio.\nOutside of work, Alex is a life-long martial arts enthusiast (Tang Soo Do, Small Circle Jujitsu, and Tai Chi). He also loves handstands (calisthenics exercise), and is very into home improvement.\n\nCareer Sketch\n\n\n\n\n\n\n\nRStudio Solutions Engineering\n2019 -\n\n\nData Science + Data Science Manager\nAnalyst Institute, Booz Allen Hamilton\n2016 - 2019\n\n\nThink Tank Times II\nBipartisan Policy Center, Brookings Institution\n2013 - 2016\n\n\nGrad School (PhD Dropout/MA)\nDuke University, Economics\n2012 - 2013\n\n\nThink Tank Times I\nBrookings Institution\n2010 - 2012\n\n\nUndergrad (BA)\nWesleyan University, Math + Econ Major\n2006 - 2010"
  },
  {
    "objectID": "mfy.html#my-definition-of-management",
    "href": "mfy.html#my-definition-of-management",
    "title": "Managing the First Year",
    "section": "My definition of management",
    "text": "My definition of management\nI’ve found management most exciting as a form of leverage. I could only ever type so many lines of code in a day, fit so many models, deploy so many apps. Management was a way to scale myself.\nAs best I can explain it:\n\nGood management is a flywheel generator — it gives the team clarity and helps them feel safe to experiment and grow, resulting in ever-higher levels of collective performance.\n\nReading this clever and finely worded definition fills me with the warm glow of a concept well-encapsulated. But let’s be honest, you — reader — are reading in hopes of being a better manager or, maybe even more likely, understanding why your manager is so bad.\n\nThe philosophers have only interpreted the world, in various ways. The point, however, is to change it.\n- Karl Marx, Eleven Theses on Feuerbach\n\nIf you’re looking to change the circumstances of your management or managing, this definition is maddeningly vague.\nWhen I started in on all those management books, I figured management would be like other things I had done in my professional life. When I wanted to do machine learning, I’d read some books and then used machine learning techniques on some data.\nBut it turned out management didn’t work like that. It turned out management was a craft.\nAnd like any craft, some theory was helpful, but the hard part was putting that theory into practice."
  },
  {
    "objectID": "mfy.html#management-was-hard",
    "href": "mfy.html#management-was-hard",
    "title": "Managing the First Year",
    "section": "Management was hard",
    "text": "Management was hard\nUnlike data science, where learning more was the answer to a skills gap, my time spent in books didn’t seem to translate directly into being better at my job.\nAs a manager, I found that it wasn’t knowledge I needed, it was the daily practice of doing the work. And in that, I was constantly bumping up against the limits of my bravery and patience.\n\nStay awkward, brave, and kind.\n-Brené Brown\n\nWhen I came back from my honeymoon, I let my ego and my fear of being wrong again get the better of me. I knew that the code and the plots weren’t good enough, and my review could have caught it. I decided that all of the team’s code would be checked into git every night and I would review it.\nThis was a dumb rule – for many reasons.\nThe simplest reason it was dumb was that I’d neglected my first role as a manager – to make the team work well. The people on my team were smart, so this mistake wasn’t an issue of intelligence. Instead, I hadn’t shared enough context about these plots so my team could catch the mistakes themselves.\nShortly after this incident got resolved, I adopted the maxim always provide more context. I found that every minute I put into providing context around why the work was the way it was paid back 10x later on. My team was made up of motivated, smart people, so once they had the necessary context, it was easy for them to spot mistakes or find improvements.\nFor a few weeks after the imposition of my new rules, I found myself in the midst of a howling maelstrom. People were not listening to the new rules, they weren’t doing their work, and they were even threatening to leave for another project.\nAnd I couldn’t figure out why the response had been so extreme. Sure, my rules might be silly, but the response seemed very intense.\nIt gradually dawned on me that I had touched a live wire. People’s work matters to them. It bumps up against the deepest questions they ask themselves about their value and worthiness.\nAnd in my haste to “fix the problem”, I had infantilized the team. And for my team, mostly recent college grads, the intimation that they still might be children after 16+ years of school was about the worst thing I could do.\nEven worse, the new rules were a source of fear. One of the main rules was that code had to be checked into git every night. From my own experience, I knew how hard git is. It is so hard to develop a reliable mental model, and it feels like all the code might go poof with any action.1 And I told my team they had to use it constantly, with no help or guidance from me.\nA big component of the problem was me struggling to manage my own fears and insecurities. I watched my team doing fantastic technical work while I perceived the atrophy of my own technical skills. For me, the challenge was avoiding slipping into defensiveness at that thought. To make it all harder – and I’ve read enough to believe this is true of all managers – I got shockingly little feedback on how I was doing.2\nMostly for worse – but some for better – my commute to this job was quite lengthy, and I listened to this episode of the excellent Start Up Podcast in which someone says the line, “organizations magnify the worst traits of their leaders”. I have seen nothing that makes me think this is anything less than 100% true.\nMy only piece of truly directive advice for any new managers reading this essay:\n\nGo do therapy/counseling.\n\nWe all have traits and quirks that are maladaptive in a management role. Therapy won’t fix them, but it certainly helped me be more aware of my tendencies and patterns, more able to step outside and observe them, and (I hope) reduced the likelihood I unwittingly perpetuated them on my team.\nEventually, once I grasped that the main thing I was actually doing was providing context and managing feelings, and things started going much smoother. Instead of walking into work every day thinking through some technical challenge or another, I tried to activate the best of my bravery and patience for the day ahead and I started digging myself out of the hole I’d fallen in with the team."
  },
  {
    "objectID": "mfy.html#management-was-just-a-bunch-of-roles-smashed-together",
    "href": "mfy.html#management-was-just-a-bunch-of-roles-smashed-together",
    "title": "Managing the First Year",
    "section": "Management was just a bunch of roles smashed together",
    "text": "Management was just a bunch of roles smashed together\nNow that you’re bought into the idea that management can’t really be learned from a book or essay, I’m going to go into my mental model of management.\nIt’s true that a mental model didn’t save me from big mistakes. But it’s also the case that one of my earliest barriers to getting better was not understanding what management was. I didn’t even know what I should be trying to improve.\nHopefully, sharing my mental model can clarify what things you might want to get better at.\nCentral to my mental model of management is that it isn’t actually a role. Manager is a title applied to a collection of largely distinct roles.\nBefore I became a manager, I had heard that management is exhausting because of the amount of context switching required. It turned out for me that this was less about having a calendar packed full of meetings with different people on different topics than it was about having to switch the role I was playing from minute to minute.\n\nA manager’s output = The output of his organization + The output of the neighboring organizations under his influence.\n-Andy Grove, High Output Management\n\nIt felt to me like there were six roles to my job as a manager, from most to least “manager-y”:\n\nAs a people manager, I learned what made my direct reports tick, identified their career aspirations, and pointed out opportunities for progress.\nAs a resource manager, I determined what resources we needed and acquired them. Mostly this meant recruiting, hiring, and onboarding, but it also meant advocating for money for training and team activities.\nAs a project manager, I collected and triaged projects and project requirements, set timetables and schedules, assigned tasks, and had the final say about when work was “done”.\nAs the team’s communications manager, I made sure the team’s work was being shared with the rest of the organization, and that everyone on the team knew what was going on outside.\nAs the process manager, I helped design the team’s processes to make sure we could identify, allot, do, and communicate work across the team.\nAs a technical mentor and coach, I was an expert who reviewed code, answered technical questions, and gave work feedback to my team.\n\nFor the most part, these roles felt pretty distinct from each other, and each of them was a meaningful part of my job.\nIn fact, in recognition of the fact I was working at a consulting firm where people frequently changed projects, my role was explicitly divided between my role as a people (“career”) manager and a “job lead” who managed a particular project and its resources.\nI found that I actually liked this division, as it gave more opportunities to acquire mentors and mentorship. Also, career conversations were truly about career – I wasn’t close enough to the work that status updates made much sense.\nMy technical skills were relevant in many of these roles – but not in the way I had thought. For the most junior employees, my skills outmatched theirs, and I was able to explicitly teach them technical things. But more senior people on the team quickly matched or exceeded my skills.\nThe primary relationship between my data science skills and my skills as a data science manager was that my technical skills helped me ask the right questions. Ultimately, my direct reports succeeded and learned more when they were asked questions than when given answers.\n\nMeetings were my main tool\nMy first, and most obvious, observation about being a manager was that nothing I did was a solo activity. In the work world, any gathering of two or more people is a meeting. Thus, meetings were my main tool as a manager.\nThe meetings varied widely in both form and content. Many were 1-1 meetings between a direct report and, others were team-wide update or decision-making meetings.\nPrimal disdain for meetings is pretty common in tech circles. I believe this is a toxic overreaction to cultures where meetings are all that happens or a result of environments (or people) that undervalue the importance of communication. I came to believe that meetings per se were not the problem.\nInstead, I came to believe meetings are bad when they:\n\nResult in calendar fragmentation.\nFeel useless to attendees.\n\nPreventing calendar fragmentation is a genuinely hard problem. Meetings tend to migrate to places where there are large open blocks of time on people’s calendars. There’s definitely no one-size-fits-all solution, but a focus-time-first orientation to making calendars can help. Aside from that, I found no great solutions here aside from trying to minimize the number of meetings and their size.\nThere have been so many books written on making meetings (feel) useful. Generally, they present a system or tactic to make meetings (feel) useful. Amazon makes everyone read a memo before they start. Tim Ferris won’t show up if there isn’t an agenda ahead of time. 1-1s are supposed to be “the employee’s meeting” where they come with an agenda and get to do most of the talking.\nThey’re fine rules.\nBut I think the focus on tactics often missed the point. Let’s take the example of 1-1 meetings with direct reports, which I found incredibly valuable – even fun!\nUp to the point I became a manager, I didn’t have great experiences with 1-1s. Most of my career didn’t feature formal 1-1s, and the one manager who adopted a real 1-1 playbook managed to make them a potent source of toxicity, format notwithstanding.\nSo, I walked into management really confused about how to do good 1-1s, and deeply skeptical of prescriptive formats.\n\nMy skepticism about meeting formats was later deepened by my first manager at RStudio.\nI loved our 1-1s despite (or because?) he broke every 1-1 rule I’ve ever seen. He talked more than he listened, meandered to wild places, and we never kept an agenda. But each one made me feel valued and seen and I left with clarity about my work. They were amazing.\n\nIn the meetings I ran, I found it was important to make clear why we were there and actually focus on that why in the meeting. Sometimes the tactics from books were helpful…but it constantly varied meeting to meeting and I struggled to taxonomize the meetings or tactics.\nKeeping the focus on what we were there to do never went wrong.\n\nHaving meetings (or parts of meetings) for frivolous fun or to get to know each other is really important – doubly so for remote teams. Just make clear that’s what they’re for!\n\nThe one kind of meeting that is always bad is the group brainstorm with more than about four people. Groups that large don’t do good exploratory thinking. Skip them, write a memo ahead of time, and debate options at the meeting.3"
  },
  {
    "objectID": "mfy.html#my-words-carried-a-lot-of-power",
    "href": "mfy.html#my-words-carried-a-lot-of-power",
    "title": "Managing the First Year",
    "section": "My words carried a lot of power",
    "text": "My words carried a lot of power\nIt’s important to be aware of implicit sources of power in a workplace, like identity-based privilege, technical knowledge, and tenure. Despite being pretty comfortable talking about power and privileged in my life, I was surprised by how much power was still embedded in the explicit management structure of the organization.\nI initially wanted to believe that nothing had changed because I was a manager – I could still be “one of the team”. But it quickly became obvious that my feedback – positive, negative, and even neutral – carried a weight it didn’t before.\nThis shouldn’t have been surprising. I’d had the experience of a manager who would frequently message “have a minute to talk?”. Every single time, my heart jumped into my throat, even though it was usually just to chat about something minor.\nAfter I observed myself doing the same, I tried to always explain why in the same message as a request to meet with a direct report.\nEven more navel-gaze-y, I realized that the form and timing of my communication mattered, because they implicitly set expectations about work habits for others.\nI tried really hard not to send messages outside of work hours – and I made a big deal of visibly unplugging when I went on vacation. I felt those were important norms for our team, and the easiest way to upend them would’ve been to be seen not following them myself.\nIt took me a while to calibrate just how often – and quickly – I had to give feedback.4 I found that critical feedback has a way shorter half-life than I assumed.\nThe first few times I had critical feedback I held it, waiting for a convenient time. But after I’d waited a week, it felt petty to bust out, “Remember that presentation last week? You really should’ve proofread it before we showed a typo to the client.” And I was worried it’d be blown out of proportion in my direct report’s head because it had bothered me enough to hold onto for so long.\nI never delivered that feedback.\nI found the quicker I could give critical feedback, the better – and that the same was also true for positive feedback.\nI don’t have a great anecdote from when I was managing, but a good friend of mine was getting very little feedback at her job. She didn’t really know if she was doing well and didn’t feel like her role was valued in the organization – until the day she resigned.\nSuddenly, accolades were pouring in from leadership across the organization - all the way up to the organization’s head. She was told for the first time that the program she ran made a difference, and that her role was essential. She was personally lauded for the grace, professionalism, and strategic thinking she brought into every meeting.\nIt meant she left feeling good, but what an utter failure of management!"
  },
  {
    "objectID": "mfy.html#some-challenges-i-could-identify-but-couldnt-solve",
    "href": "mfy.html#some-challenges-i-could-identify-but-couldnt-solve",
    "title": "Managing the First Year",
    "section": "Some challenges I could identify, but couldn’t solve",
    "text": "Some challenges I could identify, but couldn’t solve\nAside from the many skills I had to learn and the day-to-day skills I had to develop, some of the roles I inhabited as a manager involved ongoing balancing challenges that I don’t think ever really end.\n\nI was stuck in-between\nOne of the strangest parts of being a first-level manager was how much I felt stuck between the organization above me and the people who worked for me.\nI believe my employer genuinely wanted to treat employees well. They were not trying to – as Jack so eloquently put it on 30 Rock – “squeeze the sweetest juice out of workers’ mind grapes.”\nEven so, I felt a tension between looking out for the company and looking out for my direct reports. In those cases, I generally found it easy to prioritize the people who worked for me. This was especially true since it was many of their first jobs and they hadn’t quite figured out how to advocate for themselves in a workplace.\nThis materialized in simple ways, like with the woman on my team who was a dual citizen. The complexities of having multiple passports and working on projects for the federal government meant she couldn’t visit her parents while she was on the project. It was easy for me to frequently ask whether that was still ok or whether we should start looking for another project.\nBut there were also other cases that were much harder – where there was a tension between my role as a mentor for particular members of my team and my responsibilities to the team as a whole.\nFor example, someone on the team confidentially shared that she was considering another project that would give her more exposure to machine learning. From my perspective as her professional mentor, this was awesome - that was the work she really wanted to do!\nBut it was hard for me to keep this information confidential, because sitting on it meant less time to discuss what to do if she left, and more stress for the rest of the team down the road.\nMy sense is that exactly what you’re stuck between does change depending on the level of management…but I’m not sure this between-ness ever really resolves.\n\n\nResource management was particularly hard\nI despise the use of the term resource to describe a person on a team, like, “we’re going to need to add a resource in Q3” 🤮.\nBut the main resource I managed was the number of people we had and the roles they filled. I found that figuring out the right number of people for our team was an entirely new skill to master.\nBefore I was a manager, I basically just had to figure out how hard to work.\nAs a manager, I gained the mind-bending ability to make more time by adding people. Simultaneously deciding how much work the team could take on and how many people we needed required solving an underdetermined system of equations.\nWith no clear right answer, I had to rely on my judgment about the importance of the marginal bit of work and how quickly we could add team members.\nAnd it wasn’t even that simple! Because I was a stuck-between manager, I couldn’t just decide to add more people or even to spend money on other things like a course or a team dinner – I had to convince several layers of management above me that we needed them.\nDeciding how hard to push – and when - and for what roles – is a challenge that I don’t think ever really ends.\n\n\nMentoring was different\nI knew I was a good data scientist with a particularly strong background in econometrics and statistics, and I had become a very proficient R programmer. I had done a lot of teaching, which I loved. I figured I had the mentoring part of the job in the bag.\nYet again – wrong.\nIt turned out that I was good at teaching and instructing. I was good at clearly explaining technical topics, making them clear and approachable. That was useful.\nBut it turned out that an even bigger part of mentoring as a manager was coaching, rather than teaching. I had to help my direct reports develop an inspiring vision for their career – or at least for their involvement in the current project. It was a heady task – figuring out how to convey really high expectations for people without setting short-term goals or deadlines that were unreasonable.\nMoreover, it was hard to figure out how to balance people’s need for development, letting them slow down and take time to learn, with the need to get stuff done in the quickest way possible. As a manager, it was my responsibility to figure out when we had to focus on efficiency and when there were good opportunities for learning."
  },
  {
    "objectID": "mfy.html#i-loved-management",
    "href": "mfy.html#i-loved-management",
    "title": "Managing the First Year",
    "section": "I loved management",
    "text": "I loved management\nI’ve mostly written about how hard management was and how it defied my expectations.\nThat’s all true.\nBut it’s also the case that I loved my role as a manager. I experienced so much joy as I watched the connections between the people on my team get denser, and the team’s topology came more to resemble a spiderweb than a wagon wheel with me at the center.\nI found, curiously enough, that my joy at seeing what the team accomplished was inversely proportional to my involvement in it.\nNow, having been at RStudio almost three years and being back in management, I look back quite fondly on that hectic, intense, learning-filled first year.\nMy hope is that, if you’ve read this far, you’ve gotten a nugget or two that might help your own transition.\nSo, if you’re there – good luck!"
  },
  {
    "objectID": "speaking.html",
    "href": "speaking.html",
    "title": "Recent Speaking",
    "section": "",
    "text": "Selected slides are available at speakerdeck.\nGenerally, my presentations involve demoing R code, which is available on GitHub."
  },
  {
    "objectID": "index.html#essay-managing-the-first-year",
    "href": "index.html#essay-managing-the-first-year",
    "title": "Alex K Gold",
    "section": "Essay: Managing the First Year",
    "text": "Essay: Managing the First Year\nAn essay about the (many) lessons I learned in my first year of managing a data science team."
  },
  {
    "objectID": "index.html#devops-4-data-science",
    "href": "index.html#devops-4-data-science",
    "title": "Alex K Gold",
    "section": "📕🏗DevOps 4 Data Science🏗📕",
    "text": "📕🏗DevOps 4 Data Science🏗📕\nAn book on lessons for Data Scientists from DevOps, how to manage your own server-based data science platform, and how to work with IT at your organization.\nVery much a work in progress. Expected completion of rough draft: June 2022."
  },
  {
    "objectID": "posts/2019-11-09-custom-fonts-in-ggplot2/index.html",
    "href": "posts/2019-11-09-custom-fonts-in-ggplot2/index.html",
    "title": "Custom fonts in ggplot2",
    "section": "",
    "text": "A lot of things are great and easy to do in ggplot2…but putting new fonts in can be a pain in the butt. I had to do this last week, so I decided to write down what I did (as much for me as for anyone else).\n\nGet the package extrafont: install.packages('extrafont')\nStart extrafont: library(extrafont)\nImport system fonts to R (this can take a minute): font_import()\nLoad fonts: loadfonts(device = 'win'). If you’re on a Mac, just loadfonts().\nFonts are loaded!\n\nNow, when you type windowsFonts() in windows or , you’ll get a list of all available fonts:\n$serif\n[1] \"TT Times New Roman\"\n\n$sans\n[1] \"TT Arial\"\n\n$mono\n[1] \"TT Courier New\"\n\n$`Agency FB`\n[1] \"Agency FB\"\n\n$Algerian\n[1] \"Algerian\"\n\n$`Arial Black`\n[1] \"Arial Black\"\n\n$Arial\n[1] \"Arial\"\n...\nNow, when you want to use a font in ggplot, it’s as easy as calling theme(family = 'Arial').\nNote that if you’re on a Mac, you won’t get the default Microsoft Office fonts, so if you’re trying to convince people that you can switch from Powerpoint by making Excel-like plot styles, you’ll need to add the fonts manually. Luckily, it’s really easy to do through the font book utility on your Mac (just type Font into spotlight), and this blog post."
  },
  {
    "objectID": "posts/2019-07-07-r-big-data/index.html",
    "href": "posts/2019-07-07-r-big-data/index.html",
    "title": "RViews: 3 Big Data Strategies for R",
    "section": "",
    "text": "RViews Post"
  },
  {
    "objectID": "posts/2019-11-09-upgrading-to-r-rstudio-conf-2019/index.html#upgrading-to-r",
    "href": "posts/2019-11-09-upgrading-to-r-rstudio-conf-2019/index.html#upgrading-to-r",
    "title": "Upgrading to R: RStudio Conf 2019",
    "section": "Upgrading to R",
    "text": "Upgrading to R\nSo many data scientists have had the same experience - walking onto a team where something other than R or Python was the language of choice. Unless that other language was Julia or Scala, this was almost certainly a disappointing moment. But it doesn’t have a be a reason to run screaming for the hills.\nI’ve now worked on several teams that have successfully transitioned from Excel or Stata to R. These transitions, while sometimes painful, were definitely worth it. Along the way, I learned a few tips and made a lot of mistakes. I decided I’d try to share as much as possible to help anyone else in the same boat. These lessons will be particularly applicable to someone leading a data science team that’s transitioning. Some will also be relevant if you’re a junior staffer trying to push change, but not all.\nIn thinking about the transitions I’ve been part of, here are tips that might’ve helped me if I’d known them when I started. Links will be added as the posts go live.\nEdit: I seem to have fallen behind on these; maybe I’ll finish someday…"
  },
  {
    "objectID": "posts/2019-11-09-upgrading-to-r-rstudio-conf-2019/index.html#the-tips",
    "href": "posts/2019-11-09-upgrading-to-r-rstudio-conf-2019/index.html#the-tips",
    "title": "Upgrading to R: RStudio Conf 2019",
    "section": "The Tips",
    "text": "The Tips\n\nExcitement >> Skills\nFailure’s Coming, Get Ready\nYou are the Data Engineer your Team Needs\nIt Takes a Team to Write a Package\nGit: Sometimes the Right Thing isn’t the Easiest\nHave you met my Friend RMarkdown?\nDon’t Get Too Excited Just Yet\n\nI plan to write a blog post on each of these, plus an extra about how I put together these tips and the accompanying plots."
  },
  {
    "objectID": "posts/2020-12-02-practical-package-patterns/practical-package-patterns.html#the-wizard-package",
    "href": "posts/2020-12-02-practical-package-patterns/practical-package-patterns.html#the-wizard-package",
    "title": "R Packages for Experts, not Wizards",
    "section": "The Wizard Package",
    "text": "The Wizard Package\nWhen I wrote my team’s packages, I was the R wizard on the team – and if you’re reading this, you probably are too. I believed I could go off, write a package, and deliver it from on high a la Moses from Mount Sinai.1\nI’ve come to call the result of this (not so great) pattern the Wizard Package.\nWizard Packages can work. I’ve seen Wizard Packages work when (1) the whole team is clear that a package will solve the problem, (2) the need is can be met by clever R code, and (3) the team is strongly motivated to adopt the package.\nIn my case, none of these conditions held. I wasn’t riding a wave of enthusiasm for R – I was trying to spark it. People weren’t super motivated to adopt the package, and I couldn’t really compel them to do so. Worst of all, my R code just wasn’t solving the keenest problems of my teammates.\nBecause they’re written by R wizards, Wizard Packages tend to solve R wizard problems. They have clever wrappers for other functions, or convenience functions for advanced R users.\nVery often though, the team’s needs aren’t needs that are solved primarily by clever R code – the team needs to get their R Markdown report formatted with the right CSS, or calculate correct standard errors from a complicated estimator, or complete those weird database merges that only one person on the team knows how to do.2\nWizard packages convey expertise of a sort, but they often aren’t adopted because they’re not expert enough, or aren’t expert in the right ways."
  },
  {
    "objectID": "posts/2020-12-02-practical-package-patterns/practical-package-patterns.html#expert-packages",
    "href": "posts/2020-12-02-practical-package-patterns/practical-package-patterns.html#expert-packages",
    "title": "R Packages for Experts, not Wizards",
    "section": "Expert Packages",
    "text": "Expert Packages\nR packages are a tool to make your team’s expertise real. By incorporating knowledge from everyone on the team, you can create a package that disseminates that expertise to everyone on the team.\nThere’s tons of psych research (that I’m too lazy to actually cite) that one of the best ways to get someone excited about something is to get their help with it.\nMore importantly, there’s far more to package development than writing R code, so the process really can include everyone, regardless of their level of comfort with R.\nA few ways for folks to help out who might not be the R wizards:\n\nDesigning the API Even folks who are novice R developers probably have a strong sense about what the important features and options are for things like plotting the data.\nDesigning the data model Someone who knows the problem really well probably has the best sense of what the important parts of the data are to keep track of.\nSharing expert knowledge An Expert Package shares expertise across the team. By collecting that knowledge directly, you can incorporate someone’s data vis, database access, or stats expertise without needing them to write R code.\nWriting documentation, tests, or vignettes Internal packages often include documentation or vignettes that go beyond just explaining the functions themselves, but providing some context on why the function works as it does. People can also provide feedback on whether package tests are meaningful."
  },
  {
    "objectID": "posts/2020-12-02-practical-package-patterns/practical-package-patterns.html#make-your-packages-experts-not-wizards",
    "href": "posts/2020-12-02-practical-package-patterns/practical-package-patterns.html#make-your-packages-experts-not-wizards",
    "title": "R Packages for Experts, not Wizards",
    "section": "Make Your Packages Experts, not Wizards",
    "text": "Make Your Packages Experts, not Wizards\nThere’s a reason that so many stories of Wizards include dark endings, evil omens, and fallen mages. Wizardry is ineherently disconnected from others, and it’s all about being clever.\nIn the land of R packages, being expert is so much more valuable than being clever – doubly so if you can provide expertise and value to others on your team, and the number one way to do that is to get your teammates involved in the package creation process the whole way along."
  },
  {
    "objectID": "posts/2019-11-09-rstats-nyc-2017/index.html#deep-thoughts",
    "href": "posts/2019-11-09-rstats-nyc-2017/index.html#deep-thoughts",
    "title": "RStats NYC 2017",
    "section": "Deep Thoughts",
    "text": "Deep Thoughts\nMany of the speakers shared some great nuggets of insight into doing data science that extended far beyond simple lessons about R. Some of my favorites below.\n\nThe Past, Present, and Future of Data Science\n\nStatistics has gradually added different parts of the statistical process to the field — but many process points remain to be integrated. We don’t have a theory of a good statistical workflow. Meta-systematization is needed. We need to systematize how we systematize things.\nWhy do we need theory? Theory is scalable. Simulations are not.\nWe should be specifying priors about effect sizes along with research designs.\nIs having a core data science team at a company a good thing or a bad thing?\nThe history of software engineering is a great guide for the future of data science.\nAs data gets bigger, machine learning problems and questions will get bigger too. Our jobs are safe.\nThe hardest job of a data scientist is turning open-ended problems in the real world into practical problem statements that are solvable using data. Defining success is essential.\nSoftware engineers build and grow software — the sky is the limit. Data scientists are scientists and are constrained by the real world.\n\n\n\nData Science as Business Intelligence (and Empathy)\n\nAnalysis doesn’t end at result delivery — it ends at developing and proselytizing new business strategies and innovation.\nAutomating Excel workflows can be a first step towards bringing R to a team.\nAgile development tells user stories as an empathy hack.\n\n\nAs a ______\nI want ______\nSo I can ______ \n\nPerson-level stories (the near) are always more meaningful than data stories (the far). We need to balance both as Data Scientists.\nIn development, we need to have an actual user in mind, rather than a theoretical user who wants everything.\n\n\n\nHow to Live-Tweet an Event (a great aside)\n\nThree important elements in live tweet of event: conference hashtag #rstatsnyc, @speaker (put . first so it’s viewable publicly), always include a pic.\nThey can have one of a few purposes: intro person/topic, spread insight, link to resource, spread positivity!\n\nLive tweet: conference hashtag, @speaker, picture, positivity {{< tweet 855792361527541760 >}}\n\n\nHow to Hackathon\n\nIf you’re not at risk of failing a few days a quarter, you’re not pushing.\nKeys to focused hacking: rock solid infrastrure, minimize context switching (away messages), parallel work, strong and clear conversation, timeline accountability (detailed to the half-hour), positive team dynamic, time-boxing decisions.\nHow to start an analysis:\n\nIdentify assumptions about a solution\nRank assumptions by how critical they are\nTest assumptions with the simplest experiment possible\n\nFail fast. The worst thing about spending a few months barking up the wrong tree isn’t the time or money lost — it’s team demoralization.\nTruths about data science:\n\nNerd != won’t engage with business\nShiny tool != hard problem\nShiny tool != being a smart data scientist\n\n\n\n\nOpen Source and Package-Building\n\nThe hardest step in joining the open source community is going from 0 contributions to 1.\nOpen source contributions: failing test with fix > failing test > bug report\n\nRemember to include sessionInfo()\n\nPackage release ideas:\n\nRelease quickly, but also slowly — take time to fix dumb decisions\nBlaze new trails, but don’t reinvent the wheel\nTell people about your package — then listen.\n\nPackage design: documentation > usability > performance > features"
  },
  {
    "objectID": "posts/2019-11-09-rstats-nyc-2017/index.html#interesting-research",
    "href": "posts/2019-11-09-rstats-nyc-2017/index.html#interesting-research",
    "title": "RStats NYC 2017",
    "section": "Interesting Research",
    "text": "Interesting Research\nThere were only a few presentations of actual research projects — but the ones presented were really wonderful.\n\nCell tower data can reveal interesting patterns in movement — in particular return to normal flow of people after natural disasters.\nStack Overflow has a selection of data from stack overflow — can do text analysis on it. There’s also a jobs list and an api.\nIt is possible to predict which officers in police departments will have adverse incidents with the public in order to arrange interventions. Nashville and Charlottesville are doing this. This work can save lives.\nROpenSci does peer review for R packages. Many of their packages get data from scientific databases or interface with scientific equipment."
  },
  {
    "objectID": "posts/2019-11-09-rstats-nyc-2017/index.html#statistical-and-programming-tools",
    "href": "posts/2019-11-09-rstats-nyc-2017/index.html#statistical-and-programming-tools",
    "title": "RStats NYC 2017",
    "section": "Statistical and Programming Tools",
    "text": "Statistical and Programming Tools\n\nConvolutional Neural Net: used for image recognition\nVPNs are good privacy tools, we should probably all use one."
  },
  {
    "objectID": "posts/2019-11-09-rstats-nyc-2017/index.html#r-packages-to-investigate",
    "href": "posts/2019-11-09-rstats-nyc-2017/index.html#r-packages-to-investigate",
    "title": "RStats NYC 2017",
    "section": "R Packages to Investigate",
    "text": "R Packages to Investigate\nThere were so many neat R packages mentioned over the course of the conference. Here was a short list of ones I didn’t know and wanted to look into.\n\npackrat: helps you create a package template file\nplumber: allows you to easily turn regular R code into an API\nRXKCD: add XKCD cartoons to stuff!\ntrelliscope: many-panel data vis\ncompareGroups: compare demographics and other aspects across groups\nhtmlWidgets: integrate javascript applets into R code. We want interactivity, and javascript is de-facto standard for everything having to do with interactivity.\n\nipywidgets: similar for python\n\nbroom: turn analytics output into tidy data frames\ngoodpractice: does a variety of checking for good package development practice\n\nlintr: helps check for good code style\ndevtools::spellcheck()\n\nsolidify, highcharts: commonly used presentation packages\ntidytext: help turn text into tidy data frames"
  },
  {
    "objectID": "posts/2019-11-09-rstats-nyc-2017/index.html#generally-helpful-programming-hints-tips-and-tricks",
    "href": "posts/2019-11-09-rstats-nyc-2017/index.html#generally-helpful-programming-hints-tips-and-tricks",
    "title": "RStats NYC 2017",
    "section": "Generally Helpful Programming Hints, tips, and tricks",
    "text": "Generally Helpful Programming Hints, tips, and tricks\n\nrr-init: ROpenSci package to create skeleton of project\nRun R script myscript.R from command line: Rscript myscript.R\nRStudio Server runs on port 8787 by default\nAnaconda can be used to download a local R version\nCan install entire tidy verse at once: install.packages(“tidyverse”)\nAlways choose a license for your github repo. MIT is the loosest.\nCan put an empty folder in a git repo by creating and adding a file to git touch folder/.gitkeep\nmake bash — can create a makefile (make.sh) with assigned dependencies and will only run files that have been updated since last run\nJoin R mailing list\nContributing to documentation (or improving unhelpful error messages) is a great way to get started on contributing to Open Source\nIn R save() saves multiple objects with their names as .Rda. Using load restores them into the environment. saveRds() saves a single object without its name. Restoring requires assignment a <- readRds()."
  },
  {
    "objectID": "posts/2019-11-09-rstats-nyc-2017/index.html#rstudio-hints-tips-tricks",
    "href": "posts/2019-11-09-rstats-nyc-2017/index.html#rstudio-hints-tips-tricks",
    "title": "RStats NYC 2017",
    "section": "RStudio Hints, Tips, Tricks",
    "text": "RStudio Hints, Tips, Tricks\nThe RStudio folks gave a great presentation on some tricks and tips in RStudio. Some of my favorite takeaways:\n\nRealtime inline TeX previews in RNotebooks: $EQN$\nNotebook preview — doesn’t re-run, just renders what’s been run\nCan include code chunks that run code other than R (SQL, Bash, Python). Instead of {r} in chunk header, put (e.g.) {sql connection = con, output.var = ‘varname’} and then can put SELECT statement in body that will be assigned to varname\nIf you want to include variables in SQL code, use ?varname in code.\nRStudio git integration provides nice way to view diffs\nTab autocomplete is fuzzy — just type unique letters in command and tab for rest\nShift-Tab to insert code snippets — there are built in (tools > global options > code snippets)\nStarting to type a command and then cmd + arrow up gives history of all times that command used\nCan easily go from history to console or script\nctrl + . search files, fns, etc\nCTRL + SHIFT + . search among tabs\nctrl + shift + f (“or if that’s too hard to remember, ctrl capital F”) to customize where searching\nSHIFT + ALT + k list keyboard shortcuts"
  },
  {
    "objectID": "posts/2019-11-09-upgrading-to-r-1-excitement-skills/index.html#wired-teams-enthusiasm-for-learning-r",
    "href": "posts/2019-11-09-upgrading-to-r-1-excitement-skills/index.html#wired-teams-enthusiasm-for-learning-r",
    "title": "Upgrading to R #1: Excitement >> Skills",
    "section": "Wired: Team’s enthusiasm for learning R",
    "text": "Wired: Team’s enthusiasm for learning R\nTired: How much R they already know\nThis is pretty straightforward. By far the most important factor that will determine your team’s success in transitioning to R is whether they’re excited about it, and the least important is how much they already know. Learning R just really isn’t that hard. People who are excited to learn will do it, and those who aren’t won’t. It’s that simple.\nDon’t know who’s excited and who’s not? Ask them! And don’t just ask whether they’re excited to learn R. What you really want to know is whether they’re excited to work on a team that operates with R at its core. Transitioning to R from Excel or Stata has a bunch of potential benefits. Making those benefits real requires a lot more than just writing some code. It’s a wholesale transition in terms of how the team thinks about work (see future blog posts for more on that)."
  },
  {
    "objectID": "posts/2019-11-09-upgrading-to-r-1-excitement-skills/index.html#lesser-angels",
    "href": "posts/2019-11-09-upgrading-to-r-1-excitement-skills/index.html#lesser-angels",
    "title": "Upgrading to R #1: Excitement >> Skills",
    "section": "Lesser Angels",
    "text": "Lesser Angels\nBeyond enthusiasm, there are a couple of things you can do to make it easier, whether you’re a team member or the leader.\n\nTidyverse-First Orientation: If you’ve been doing R for a while, you probably know this, but the Tidyverse is AWESOME. It takes the wonderful benefits of R and adds an opinionated take on what code should look like. If you’re just learning R, start with the Tidyverse. You’ll be glad you did because it’s magical.1\nRelentless R: Adoping R as a team isn’t really about a programming langauge, it’s organizational change. Writing code is easy. Changing hearts, minds, and workflows is hard. There are people who make whole careers out of this stuff. Don’t get down if it’s slow going. I’m skeptical it’s possible to really transition a team to R in less than 12 months.\nLearning Environment: More on this during Tip #2: Failure, but you’re trying to make room for people to learn. That means it’s important to make work a space where they won’t feel stupid for asking questions or making mistakes. Hopefully this is already true for your workplace…but it’s especially important if you’re trying to get your team to do something new and hard like use R. Every workplace is busy, but almost every one can spare an hour a week to do a mini-seminar on R, or to share a package of the week. On my team, we have a show-and-tell every Friday where people share something they’ve learned. Very often, that something is a fun new R thing!\n\nA sub-point to this: If you can, don’t expect that all this learning will take place outside of work. Some people on your team may have kids or parents they’re caring for, or other life circumstances that mean that they have less capacity to do out-of-work learning than others. They can still be amazing partners on your journey to R. If you’re the team lead, try and make space for them to learn. If not, make sure they’re included on at-work R plans."
  },
  {
    "objectID": "posts/2019-10-17-production-shiny-w-pins/index.html",
    "href": "posts/2019-10-17-production-shiny-w-pins/index.html",
    "title": "RViews: Production Shiny Apps with Pins",
    "section": "",
    "text": "RViews Post"
  },
  {
    "objectID": "posts/2019-11-09-upgrading-to-r-2-failures-coming-get-ready/index.html",
    "href": "posts/2019-11-09-upgrading-to-r-2-failures-coming-get-ready/index.html",
    "title": "Upgrading to R #2: Failure’s Coming, Get Ready!",
    "section": "",
    "text": "As a new manager working with my team of data scientists, upgrading to R meant doing something new, and something hard. As I should’ve known, new + hard is a great recipe for mistakes and failures. I learned a lot from those mistakes - lessons that I couldn’t have anticipated ahead of time. I’ll share my surprising (and less surprising) things I learned from one particular big failure in this blog post.\nTo start, here’s an animation I made that describes Alex’s big goof-up:\n\n\n\n\n\nTL;DR: my team was working hard onboarding themselves to R, a mistake made it to a client, and I overreacted with new policies that burned a lot of my team’s goodwill. Regaining the team’s trust required eating some words, retracting some policies, and a bunch of all-team discussions to figure out how to do better in the future.\nI should’ve realized that my team’s goodwill was my most precious resource as a manager. Squandering it wasn’t a simple matter of not being nice, it (thankfully temporarily) damaged my ability to effectively lead and guide them, and diminished the likelihood that they would do their best work. Here are some things I wish I’d done ahead of time.\n\nShare More Context\nAs far as my teammate knew their role in this project was to create a plot in ggplot based on some data they were given. I’d shared very little about why that plot was important, where the data was coming from, or who was the intended audience. Without that knowledge, there were a multitude of ways my teammate could make totally sensible decisions that resulted in mistakes - mistakes that could’ve been avoided had I just shared more context.\nHere’s something like the plot we were making:\n\n\n\n\n\nAmong the context I should’ve shared was that we couldn’t derive the color coding of the data points ourselves.1 Since I’d neglected make sure my teammate really understood what we were doing, my teammate just computed the color themselves (metric > threshold -> green, red otherwise). This totally reasonable choice, which resulted in mistakes the client noticed, could’ve totally been avoided had I spent a few more minutes sharing more context.\n\n\nPrepare Emotionally\nThe number 1 thing I could’ve done to make this experience less bad was to avoid overreacting.2 If I could’ve gone back to a week before we found our mistake, I would’ve told past me that a mistake was inevitable, and that I should be ready to react - not unilaterally, but by rallying the team to fix the issue together.\nThe project was important, and the client seeing a mistake was bad. But draconian new procedures and rules resulted in ill-will from my team that was ultimately way more costly.\nWhat eventually got us back on track was when we met as a team, and had a few meetings in the style of a blameless postmortem figuring out where communication had broken down and how we could avoid it next time. The guidelines we eventually generated and adopted as a group were actually pretty similar to the rules I’d introduced, but this time we were actually able to stick to them, because we’d generated them together.\n\n\nPrepare Technically\nBefore this incident,I focused 100% of my mistake-avoiding attention on technical prepartion - explicit error avoidance and checking. I’ve since come to believe that error checking is an important part of the solution, but on a team that primarily produces data insights, the number one way to avoid errors is to give analysts and data scientists the knowledge they need to find mistakes themselves.\n\nSanity Checks\nAll data scientists know the horror of finishing an analysis, breathing a huge sigh of relief, sending it off, and then realizing that something just doesn’t add up. I’ve definitely had categories that add up to more than 100 percent, some 256 year-olds, and coefficents so big they could power a trip to the moon.3\nRemembering to do these sanity checks before anything gets sent out is hard, especially since finding something might result in more work. This is doubly true for junior team members, who might not have made all these mistakes before and might not totally know what they’re looking for.\nOne strategy that helped was removing some of the cognitive load of what to check. That meant building analysis templates that included sanity checks on results, checklists for review and execution, and R packages that automated simple checks. Removing some of the cognitive load of remembering to do all these checks was relieving for junior and senior team members alike.\n\n\nCode Review\nCode review is great. But it was easy to believe only “real” code review (i.e. comments on github merge requests) mattered. More and more, I’ve come to think that the primary purpose of code review is to trigger thinking by the code’s author. Given that the author is 100x more familiar with it (to a first approximation), I found that code review that forces the writer to rethink what they’ve done catches many mistakes, and that the venue isn’t really important.\nSince this incident, my team has gotten more consistent at using git for code reviews, but we’ve also gotten better at doing low-tech code review. Any review, no matter how low-tech, is 1,000x better than code review that didn’t happen because I was waiting for the team to “get up to speed with git”. Sometimes I even like to print out code, read through it, and mark it up like an essay. Decidedly low-tech, but really engages the mental compiler.\n\n\n\nTakeaways\nSo, here are the big lessons I took home from my moment of failure:\n\nNew + Hard -> Failure, and being emotionally ready is at least as importance as technical preparation.\nOverreacting to a mistakes as a manager can cause a bigger problem than the mistake itself.\nAlways share more context.\nTechnical solutions like templates, checklists, packages, and code review are great, but mostly because they reduce cognitive load of simple checks, or because they force the author to reengage.\n\n\n\nA Coda: Book Recs\nI can’t leave this blog post without sharing three book recommendations that really helped me. While the screw up I describe here is real, I wasn’t entirely without tools to cope, and these three books helped form my mental model for how we might think about recovery as a team.\n\nRising Strong by Brene Brown is a great exploration of failure and recovery, it provides some interesting perspectives on failure and resilience from both a personal and professional level.\nHigh Output Management by Andy Grove is a pretty traditional “management” book, and his explanation of managing to task-relevant maturity has been a helpful way to think about helping the people I manage (or helping my managers help me) avoid potential mistakes and failures.\nChecklist Manifesto by Atul Gawande is one of my all time favorite books, and it really influenced the way I think about what should be automated vs checklisted vs left up to humans.\n\n\n\n\nFootnotes\n\n\nTo be precise, whether the difference between the metric and the threshold was statistically significant, which we didn’t have the data to compute ourselves.↩︎\nEspecially if you’re the team lead, but really no matter what.↩︎\nOr more likely 999 year-olds. Missing data should never have numeric codes, amirite?!?↩︎"
  },
  {
    "objectID": "posts/2019-11-09-upgrading-to-r-3-be-the-data-engineer-you-need/index.html",
    "href": "posts/2019-11-09-upgrading-to-r-3-be-the-data-engineer-you-need/index.html",
    "title": "Upgrading to R #3: Be the Data Engineer you Need",
    "section": "",
    "text": "When I first went to data conferences, I assumed that EVERYONE else was pulling data from a supercomputer-backed Spark cluster, immaculately maintained by an army of data engineers. Needless to say, that was not my data infrastructure.\nTo be more succinct, most of the “data infrastructure” I’ve worked with has just been csv files. And our ETL processes – cleaning csv files to output more csv files (or rds).\nBased on my very informal polling of people in the field, this is WAY more common than anyone admits, especially if you’re on a team that’s just upgrading to R. As you make that switch, it’s easy to be discouraged feeling like everyone else is lightyears ahead. The (not so) dirty secret is that they’re not really.\nIf I had to guess, the modal data scientist/analyst working in industry does ETL across a mixture of flat files and SQL databases. It’s still relatively rare to find people working on higher-power systems.1\nComing into a new role and discovering that you’re expected to wrangle a bunch of csv files can be frustrating, especially if you don’t reall ywant to be a data engineer. But you should. The number one way to be a better data scientist is to become the data engineer you wish you had.\nBeing a great junior data scientist is 75% just knowing the data super well. A junior data scientist who can confidently identify things that just look weird in data is worth approximately 47 XGBoost models and 76 convolutional neural nets.\nA data scientist who combines data science knowledge with expertise on the data’s provenance and the data-generating process is way more likely to make a good catch or identify a clever new feature for modeling than a better modeler with little understanding of the specifics of the data.\n\n\n\n\n\nSo yes, become the data engineer for your data because you need it, but also to make yourself a better data scientist. It won’t kill you.\n\nBest Practices for ETL on Flat Files\nSince I’ve done and managed a lot of ETL involving flat files, here are some tips I’d suggest:\n\nUse git to manage your code, and git LFS for managing data. Git will choke and die on data files larger than 50Mb or so, but aside from some annoyingly long download and upload times, git LFS has been a good tool for sharing data up to a few Gb across my team.\nStore all data in a data folder, with input data separated from cleaned data.\nIf feasible, create standardized cleaning functions (in a package!) so that variable names are the same across different projects.\nConsider creating a data access API in R so you call a function to access data instead of loading a csv file.2 The advantage is that it abstracts away from exactly how you store the data, so you can get used to loading your data in a simple way, and you can always update the backend to a SQL server or something else without changing the way you access your data.\n\n\n\n\nFootnotes\n\n\nOr honetly, use cases that really need those systems. Postgres will get you pretty far.↩︎\nDon’t get scared by “an API” if you’re not familiar! It just means a bunch of functions so that you can access in a consistent way.↩︎"
  }
]